{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeda840-4f98-4141-aecc-2540c288d4ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713565ad-1644-4edd-809a-e04e286dfa50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'data_translated_columns - Copy.csv' with the full path to your CSV file\n",
    "file_path = 'data_translated_columns - Copy.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Now, 'df' contains your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c33814-4ea0-4f7d-8f8b-6e7f648a490c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de506cea-9caa-4d3e-9f95-7193573719e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf49a6-b741-44ba-bb7f-cc356bd9c17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the number of rows and columns in the dataset\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a66337-12af-489f-a662-ec730b0ff492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27aea26-4c5b-4a9e-b8c6-b3f97fbe757e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f259f92-beda-494e-908f-518782abb9de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace spaces with underscores in column names\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e2e39-327e-4789-929d-8949bef44317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe80a5-04c8-4d7d-ba3b-5986dba8d40a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07340edc-3cd3-44ea-a411-f8df1dceed0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97194b7f-52d9-44ae-870e-165b90848fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986616b-c493-4933-91ad-511b2032ea02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting numeric part from the string and converting to float or integer\n",
    "df_copy['Number_of_days_until_sale'] = df_copy['Number_of_days_until_sale'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Check the unique values after transformation\n",
    "unique_values_after = df_copy['Number_of_days_until_sale'].unique()\n",
    "print(unique_values_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4992a-d5d2-40d6-99c7-c420cb11ef6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df_copy.to_csv('modified_Names_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e97544-71c9-4aa6-8cb9-66a9097ee73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file back into a DataFrame\n",
    "loaded_df = pd.read_csv('modified_Names_data.csv')\n",
    "\n",
    "# Display the first few rows of the loaded DataFrame\n",
    "print(loaded_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42804aa-7cce-4471-9018-cf4be74706b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drop the first two columns and update df_copy because they are redundant\n",
    "#df_copy = df_copy.drop(['Offered since', 'Sale date '], axis=1)\n",
    "loaded_df.drop(['Offered_since', 'Sale_date'], axis=1, inplace=True)\n",
    "# Print the columns in df_copy\n",
    "print(loaded_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b972a3-1359-4ebb-a0ff-214334a9c029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Status variable?\n",
    "\n",
    "# Display unique values in the 'Status' column\n",
    "unique_statuses = loaded_df['Status'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_statuses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c64300-cb76-4b2c-81e5-f9c2bf7e55ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Since all of the values of 'Status' are the same it will be discarded\n",
    "# Drop the 'Status' column and update df_copy\n",
    "loaded_df.drop('Status', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91983ec9-7148-44e5-a332-d74a6afa355a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display unique values in the 'Type of construction' column\n",
    "unique_construction_types = loaded_df['Type_of_construction'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_construction_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6d84d-c222-46b8-91d8-bd37fc3befd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One hot encoding Type of consruction\n",
    "df_encoded = pd.get_dummies(loaded_df, columns=['Type_of_construction'], prefix='Construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2d11c-8fbe-4a90-9a39-efc22d710d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# english of the new variables after one-hot encoding\n",
    "df_encoded = df_encoded.rename(columns={'Construction_Bestaande bouw': 'Construction_Existing', \n",
    "                                        'Construction_Nieuwbouw': 'Construction_New'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190bbf3-014d-4007-aa10-993e477e9752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b405d-c6f2-4a77-b4df-055c8bd3235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded your DataFrame 'df_encoded'\n",
    "\n",
    "# Convert boolean values to integers\n",
    "df_encoded['Construction_Existing'] = df_encoded['Construction_Existing'].astype(int)\n",
    "df_encoded['Construction_New'] = df_encoded['Construction_New'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e7dc4-b049-4853-be4a-3255f8e52c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the names of columns with data type 'object'\n",
    "object_columns = df_encoded.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Display the names of object-type columns\n",
    "print(\"Object-type columns in df_encoded:\")\n",
    "for col in object_columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5210d-d389-4c3b-95a5-c95e0c4e3b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample dataframe loading code (replace with your actual dataframe loading code)\n",
    "# df_copy = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Replace 'A+++++' with 'A+++'\n",
    "df_encoded['Energy_label'] = df_encoded['Energy_label'].replace('A+++++', 'A+++')\n",
    "\n",
    "# Assuming 'Energy_label' is the column you want to plot\n",
    "energy_labels_counts = df_encoded['Energy_label'].value_counts(dropna=False)\n",
    "\n",
    "# Set a colorful Seaborn palette (using the \"viridis\" palette)\n",
    "color_palette = sns.color_palette(\"viridis\", n_colors=len(energy_labels_counts))\n",
    "\n",
    "# Create a bar plot with enhanced styling\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = energy_labels_counts.plot(kind='bar', color=color_palette, width=0.7, edgecolor='black')\n",
    "\n",
    "# Adding a grid for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Distribution of Energy Labels (including missing values)', fontsize=16)\n",
    "plt.xlabel('Energy Label', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "\n",
    "# Rotating x-axis labels for better visibility\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "# Adding data labels on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=10)\n",
    "\n",
    "# Removing the top and right spines for aesthetics\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('energy_labels_distribution.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5a5cc-b8ce-4692-87d1-42f0a46d9b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display unique values in the 'Energy label' column\n",
    "unique_energy_labels = df_encoded['Energy_label'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values in the 'Energy_label' column:\")\n",
    "print(unique_energy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d1e22-b0b3-40ed-aab2-18aa80e64ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the most frequent label in 'Energy label'\n",
    "most_frequent_label = df_encoded['Energy_label'].mode()[0]\n",
    "\n",
    "# Replace 'None' and NaN values with the most frequent label\n",
    "df_encoded['Energy_label'] = df_encoded['Energy_label'].fillna(most_frequent_label)\n",
    "df_encoded['Energy_label'] = df_encoded['Energy_label'].replace('None', most_frequent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d330b18-6578-4b19-ad11-4cec5c0612ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display unique values in the 'Energy label' column\n",
    "unique_energy_labels = df_encoded['Energy_label'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values in the 'Energy_label' column:\")\n",
    "print(unique_energy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21715555-a6fe-430f-b40e-fd79fe489159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the custom order\n",
    "custom_order = [ 'A++++', 'A+++', 'A++', 'A+', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "\n",
    "# Initialize LabelEncoder with the custom order\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(custom_order)\n",
    "\n",
    "# Apply label encoding to the 'Energy label' column\n",
    "df_encoded['Energy_label'] = label_encoder.transform(df_encoded['Energy_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321b23b-8ef8-410a-9292-857bbbd696a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9757e-9d70-445d-b44a-08f44f948fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "# Assuming df_encoded is your DataFrame with columns 'Living space in m2' and 'Number of days until sale'\n",
    "\n",
    "# Create bins for living space and days_until_sale\n",
    "space_bins = pd.cut(df_encoded['Living_space_in_m2'], bins=10)  # You can adjust the number of bins\n",
    "days_bins = pd.cut(df_encoded['Number_of_days_until_sale'], bins=10)\n",
    "\n",
    "# Create a new DataFrame with binned data\n",
    "binned_df = pd.DataFrame({'space_bins': space_bins, 'days_bins': days_bins})\n",
    "\n",
    "# Calculate the average number of days until sale for each bin\n",
    "average_days = df_encoded.groupby([space_bins, days_bins])['Number_of_days_until_sale'].mean().reset_index(name='Avg_days_until_sale')\n",
    "\n",
    "# Create a scatter plot with color gradient\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = sns.scatterplot(x='Living_space_in_m2', y='Number_of_days_until_sale', data=df_encoded, hue=space_bins, palette='viridis', alpha=0.7)\n",
    "\n",
    "# Create a ScalarMappable object for color mapping\n",
    "sm = ScalarMappable(cmap='viridis')\n",
    "sm.set_array([])  # You need to set an array for the mappable\n",
    "\n",
    "# Get the current Axes object\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.title('TOM - LIVING SPACE')\n",
    "plt.xlabel('Living_space_in_m2')\n",
    "plt.ylabel('Number_of_days_until_sale')\n",
    "\n",
    "# Save the plot to a file (adjust the file format and name as needed)\n",
    "plt.savefig('scatter_plot_living_space.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b06ef-5f55-4b72-a756-cc6882741fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "# Assuming df_encoded is your DataFrame with columns 'Last asking price' and 'Number of days until sale'\n",
    "\n",
    "# Create bins for price and days_until_sale\n",
    "price_bins = pd.cut(df_encoded['Last_asking_price'], bins=10)  # You can adjust the number of bins\n",
    "days_bins = pd.cut(df_encoded['Number_of_days_until_sale'], bins=10)\n",
    "\n",
    "# Create a new DataFrame with binned data\n",
    "binned_df = pd.DataFrame({'price_bins': price_bins, 'days_bins': days_bins})\n",
    "\n",
    "# Calculate the average number of days until sale for each bin\n",
    "average_days = df_encoded.groupby([price_bins, days_bins])['Number_of_days_until_sale'].mean().reset_index(name='Avg_days_until_sale')\n",
    "\n",
    "# Create a scatter plot with color gradient\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = sns.scatterplot(x='Last_asking_price', y='Number_of_days_until_sale', data=df_encoded, hue=price_bins, palette='viridis', alpha=0.7)\n",
    "\n",
    "# Create a ScalarMappable object for color mapping\n",
    "sm = ScalarMappable(cmap='viridis')\n",
    "sm.set_array([])  # You need to set an array for the mappable\n",
    "\n",
    "# Get the current Axes object\n",
    "ax = plt.gca()\n",
    "\n",
    "# Modify x-axis and y-axis tick labels to include the Euro sign\n",
    "ax.set_xticklabels([f'€{tick}' for tick in ax.get_xticks()])\n",
    "\n",
    "plt.title('TOM - PRICE')\n",
    "plt.xlabel('Last_asking_price (Euro)')\n",
    "plt.ylabel('Number_of_days_until_sale')\n",
    "\n",
    "# Save the plot to a file (adjust the file format and name as needed)\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d2d47-b6e1-4e27-987f-85648ebe1aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f970454-f67a-48bd-a152-fc3e1a7037e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5bc7b-c6d2-43ee-8cb6-e6bb520b07db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546de604-e5ae-4bfb-8c3b-9f9cf841ebdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if there are any missing values in the entire DataFrame\n",
    "any_missing = df_encoded.isnull().any().any()\n",
    "\n",
    "# Display the result\n",
    "print(f\"Does the df_copy have any missing values? {any_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a42df-f6f5-4481-ac8f-655190c543ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Filter columns with 'object' data type\n",
    "object_columns = df_encoded.select_dtypes(include='object')\n",
    "\n",
    "# Display the columns with 'object' data type\n",
    "print(object_columns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddc2722-f028-450f-9dc4-ef95d89bce3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822cc2bc-44ed-4178-9407-99d71138cf37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c01fbb-4ce3-4dcf-b542-e1906e4d0e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the most frequent label in 'Energy label'\n",
    "most_frequent_label = df_encoded['Energy_label'].mode()[0]\n",
    "\n",
    "# Replace 'None' and NaN values with the most frequent label\n",
    "df_encoded['Energy_label'] = df_encoded['Energy_label'].fillna(most_frequent_label)\n",
    "df_encoded['Energy_label'] = df_encoded['Energy_label'].replace('None', most_frequent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c222c55-bce3-4938-93cb-721fd9db8794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display unique values in the 'Energy label' column\n",
    "unique_energy_labels = df_encoded['Energy_label'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values in the 'Energy label' column:\")\n",
    "print(unique_energy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a89181-319a-4489-9fd0-bf9409f4a9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5eeb49-bef9-46ea-8937-ba09a1ccc34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display unique values in the 'Energy label' column\n",
    "unique_energy_labels = df_encoded['Energy_label'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values in the 'Energy_label' column:\")\n",
    "print(unique_energy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a0804-aa02-4b3d-b42e-2d14ef125488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the names of columns with data type 'object'\n",
    "object_columns = df_encoded.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Display the names of object-type columns\n",
    "print(\"Object-type columns in df_encoded:\")\n",
    "for col in object_columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a535aa-9af8-4cf3-8c83-316b553f1be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_encoded is your DataFrame and 'Roof type' is the column you want to encode\n",
    "df_encoded['Roof_type'] = df_encoded['Roof_type'].map(df_encoded['Roof_type'].value_counts(normalize=True))\n",
    "\n",
    "# Now, 'Roof type' column is frequency-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0587ce8-a534-4b6f-8b7b-f3660e07974c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253e355-73ed-4ea8-8cac-95a12adc757a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'Roof type' is the column in your DataFrame\n",
    "unique_roof_types = df_encoded['Roof_type'].nunique()\n",
    "\n",
    "# Display the number of unique values\n",
    "print(\"Number of unique values in 'Roof_type':\", unique_roof_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f38898-1581-4dd6-9392-87ac95795ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'Type of residence' is the column in your DataFrame\n",
    "frequency_encoding = df_encoded['Type_of_residence'].value_counts(normalize=True)\n",
    "\n",
    "# Apply the frequency encoding to the 'Type of residence' column\n",
    "df_encoded['Type_of_residence'] = df_encoded['Type_of_residence'].map(frequency_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14fab4-a91a-4aca-88e0-5a83b0a0cfe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'Type of residence' is the column in your DataFrame\n",
    "unique_Type_of_residence = df_encoded['Type_of_residence'].nunique()\n",
    "\n",
    "# Display the number of unique values\n",
    "print(\"Number of unique values in 'Type_of_residence':\", unique_Type_of_residence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c38214-d1f8-44c1-9aec-a5c9023b2372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'df' is the name of your DataFrame\n",
    "df_encoded_dtypes = df_encoded.dtypes\n",
    "\n",
    "# Display the data types\n",
    "print(df_encoded_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247c9eb-8332-486c-b966-ecd4c3f0cd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34f3af-2a94-485f-a1c8-1e13f8e6d5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save df_encoded to a CSV file\n",
    "df_encoded.to_csv('df_encoded.csv', index=False)\n",
    "\n",
    "# Load the saved DataFrame from the CSV file\n",
    "df_encoded_mapping= pd.read_csv('df_encoded.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af9e6d-d2b7-4366-b6be-35c79a410292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "e_df = pd.read_csv('df_encoded.csv')\n",
    "\n",
    "# Assuming your target variable is called 'Number_of_days_until_sale'\n",
    "target_mean = e_df['Number_of_days_until_sale'].mean()\n",
    "\n",
    "print(f\"Mean of the target variable: {target_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe0927-e381-4c2f-a25c-41c88f5bdaf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "e_df = pd.read_csv('df_encoded.csv')\n",
    "\n",
    "# Assuming your target variable is called 'Number_of_days_until_sale'\n",
    "target_max = e_df['Number_of_days_until_sale'].max()\n",
    "target_min = e_df['Number_of_days_until_sale'].min()\n",
    "\n",
    "target_range = target_max - target_min\n",
    "\n",
    "print(f\"Range of the target variable: {target_range}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f414f-27cd-4501-8d99-f489cdd5206c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "\n",
    "# Custom scorer for RMSE\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Negative RMSE scorer for RFECV\n",
    "neg_rmse_scorer = make_scorer(rmse_scorer, greater_is_better=False)\n",
    "\n",
    "# Load your data (replace with your DataFrame variable)\n",
    "data = pd.read_csv('df_encoded.csv')\n",
    "X = data.drop('Number_of_days_until_sale', axis=1)\n",
    "y = data['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train_cv, X_test, y_train_cv, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize a Decision Tree Regressor for RFECV\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Initialize RFECV with the Decision Tree Regressor and 3-fold CV using RMSE as the scoring metric\n",
    "rfecv = RFECV(estimator=dt_regressor, step=1, cv=3, scoring=neg_rmse_scorer)\n",
    "\n",
    "# Fit RFECV on the training set\n",
    "rfecv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "# Print the optimal number of features and the selected features\n",
    "print(\"Optimal number of features:\", rfecv.n_features_)\n",
    "print(\"Selected features:\", X_train_cv.columns[rfecv.support_])\n",
    "\n",
    "# Transform the datasets to the selected features\n",
    "X_train_selected = rfecv.transform(X_train_cv)\n",
    "X_test_selected = rfecv.transform(X_test)\n",
    "\n",
    "# Train a model using the selected features from the training set\n",
    "dt_regressor.fit(X_train_selected, y_train_cv)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = dt_regressor.predict(X_test_selected)\n",
    "\n",
    "# Calculate and print performance metrics\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test R2: {test_r2}, MSE: {test_mse}, RMSE: {test_rmse}, MAE: {test_mae}\")\n",
    "\n",
    "# Get the feature importances from the trained Decision Tree Regressor\n",
    "importances = dt_regressor.feature_importances_\n",
    "\n",
    "# Match these importances with the feature names\n",
    "feature_names = X_train_cv.columns[rfecv.support_]\n",
    "\n",
    "# Normalize the importances (scale between 0 and 1)\n",
    "importances_normalized = importances / importances.max()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances_normalized})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting with 'viridis' color palette, scaled 0 to 1\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances, palette='viridis')\n",
    "plt.title('Features Selected by RFECV')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels\n",
    "plt.yticks(rotation=45)  # Rotate y-axis labels\n",
    "\n",
    "# Save the plot with 'viridis' color palette\n",
    "plt.savefig('RFECV_feature_importances_viridis_rotated.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65f1ae-871a-4b01-b69c-88264a20e051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only the selected important features and the target variable\n",
    "reduced_df_rfecvdt = data[['Last_asking_price', 'Energy_label', 'Plot_area_in_m2',\n",
    "       'Backyard_area_in_m2', 'Asking_price_per_m2', 'Living_space_in_m2',\n",
    "       'Building-related_outdoor_area_in_m2', 'External_storage_area_in_m2',\n",
    "       'Volume_in_m3', 'Number_of_bedrooms', 'Fully_insulated',\n",
    "       'Partial_underfloor_heating', 'Indoor_storage', 'Storage_box',\n",
    "       'Backyard', 'Roof_type', 'Type_of_residence', 'Construction_Existing','Number_of_days_until_sale']]\n",
    "\n",
    "# Save the reduced dataset to a new CSV file\n",
    "reduced_df_rfecvdt.to_csv('reduced_df_rfecvdt.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e71dd9-07e7-44f6-a725-ffdf5e76ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after reducing data eith rfecv and full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d505c-7c3f-478d-9f8a-04458ec13b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#####OLS full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb3e51-c202-45a5-b224-6d1728092cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('df_encoded.csv')\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Add a constant term to the independent variables matrix (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the OLS model\n",
    "ols_model = sm.OLS(y_train, X_train)\n",
    "\n",
    "# Fit the model\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# Print the summary of OLS regression results\n",
    "print(ols_results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = ols_results.predict(X_test)\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(\"R-squared:\", test_r2)\n",
    "print(\"MAE:\", test_mae)\n",
    "print(\"RMSE:\", test_rmse)\n",
    "\n",
    "# Create and save a scatter plot of actual vs predicted values with purple dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='blue')  # Set color to 'purple' for the dots\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - OLS (Full dataset)')\n",
    "plt.savefig('actual_vs_predicted_OLS_Fulldata.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7f0f4-bacf-4f23-81d7-a06b93f3c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####linear regression RFECVDT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc3d54-56ff-40b0-9208-7231646ef835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reduced_df_rfecvdt.csv')\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Add a constant term to the independent variables matrix (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the OLS model\n",
    "ols_model = sm.OLS(y_train, X_train)\n",
    "\n",
    "# Fit the model\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# Print the summary of OLS regression results\n",
    "print(ols_results.summary())\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = ols_results.predict(X_test)\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(\"R-squared:\", test_r2)\n",
    "print(\"MAE:\", test_mae)\n",
    "print(\"RMSE:\", test_rmse)\n",
    "\n",
    "# Create a scatter plot of actual vs predicted values with blue dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - OLS (RFECV)')\n",
    "\n",
    "# Save the scatter plot as an image\n",
    "plt.savefig('actual_vs_predicted_OLS_RFECV.png')\n",
    "\n",
    "# Display the scatter plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75175106-a402-4129-909f-10143b10767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestFull dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d3bfe-3636-4222-9633-6a8a680e1f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('df_encoded.csv')  # Replace with your actual file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)  # Replace with your target column name\n",
    "y = df['Number_of_days_until_sale']               # Replace with your target column name\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform 3-fold cross-validation on the training data and calculate metrics\n",
    "cv_r2_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=3, scoring='r2')\n",
    "cv_mae_scores_rf = -cross_val_score(rf_model, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')\n",
    "cv_rmse_scores_rf = np.sqrt(-cross_val_score(rf_model, X_train, y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Normalize the importances (scale between 0 and 1)\n",
    "importance_df['Importance'] = importance_df['Importance'] / importance_df['Importance'].max()\n",
    "\n",
    "# Select top 18 features\n",
    "top_features = importance_df.nlargest(18, 'Importance')\n",
    "\n",
    "# Plotting feature importances and saving the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n",
    "plt.title('Top 18 Features Selected by Random Forest')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels\n",
    "plt.yticks(rotation=45)  # Rotate y-axis labels\n",
    "plt.savefig('feature_importances_RF_plot.png', dpi=300, bbox_inches='tight')  # Save the plot to a file\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a scatter plot of actual vs predicted values with blue dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='blue')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - Rndom Forest (Full dataset)')\n",
    "\n",
    "# Save the scatter plot as an image\n",
    "plt.savefig('actual_vs_predicted_RF_Fulldata.png')\n",
    "\n",
    "# Display the scatter plot\n",
    "plt.show()\n",
    "\n",
    "# Save the top 18 features with the target variable to CSV\n",
    "important_features_data = df[top_features['Feature'].tolist() + ['Number_of_days_until_sale']]\n",
    "important_features_data.to_csv('RandomForest_important_features_data.csv', index=False)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", cv_r2_scores_rf)\n",
    "print(\"Cross-Validation MAE scores:\", cv_mae_scores_rf)\n",
    "print(\"Cross-Validation RMSE scores:\", cv_rmse_scores_rf)\n",
    "print(\"\\nTraining Set R-squared:\", train_r2)\n",
    "print(\"Training Set MAE:\", train_mae)\n",
    "print(\"Training Set RMSE:\", train_rmse)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292f81d-10dd-45cf-a0db-00167f052420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explicitly import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with important features\n",
    "important_features_data = pd.read_csv('RandomForest_important_features_data.csv')\n",
    "\n",
    "# Display the column names (variable names)\n",
    "variable_names = important_features_data.columns.tolist()\n",
    "print(\"Variable Names in 'RandomForest_important_features_data.csv':\")\n",
    "print(variable_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a6c0f-071e-4a37-9694-30fdfe15ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest with reduced Builtin and tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018fe36-5d89-4936-82a1-b3785d85be9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('RandomForest_important_features_data.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = rf_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='purple')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - Random Forest (Top 18 features)')\n",
    "plt.savefig('actual_vs_predicted_random_forest_Builtin.png') \n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", rf_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", rf_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8364a6-cf83-4435-a23e-594e2434b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest with reduced RFECVDT and tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f30ff1-afbc-402d-9cb8-90bb9b0061ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reduced_df_rfecvdt.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = rf_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - Random Forest (RFECV)')\n",
    "plt.savefig('actual_vs_predicted_random_forest_RFECV.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", rf_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", rf_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05506e2-4849-4a31-a478-64aafcc6e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XgBoost Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbcbe6-1ca9-4ca5-b5e4-50d15934a328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('df_encoded.csv')  # Replace with your actual file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)  # Replace with your target column name\n",
    "y = df['Number_of_days_until_sale']               # Replace with your target column name\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Perform 3-fold cross-validation on the training data and calculate metrics\n",
    "cv_r2_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=3, scoring='r2')\n",
    "cv_mae_scores_xgb = -cross_val_score(xgb_model, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')\n",
    "cv_rmse_scores_xgb = np.sqrt(-cross_val_score(xgb_model, X_train, y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Train the model on the training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Normalize the importances (scale between 0 and 1)\n",
    "importance_df['Importance'] = importance_df['Importance'] / importance_df['Importance'].max()\n",
    "\n",
    "# Select top 18 features\n",
    "top_features = importance_df.nlargest(18, 'Importance')\n",
    "\n",
    "# Plotting feature importances and saving the plot\n",
    "plt.figure(figsize=(10, 8))  # Adjust the size as needed\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n",
    "plt.title('Top 18 Features Selected by XGBoost ')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels\n",
    "plt.yticks(rotation=45)  # Rotate y-axis labels\n",
    "plt.tight_layout()  # This will adjust spacing to accommodate labels\n",
    "plt.savefig('feature_importances_xgboost_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a scatter plot of actual vs predicted values with blue dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='blue')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - XGBoost (Full dataset)')\n",
    "\n",
    "# Save the scatter plot as an image\n",
    "plt.savefig('actual_vs_predicted_XGBoost_Fulldata.png')\n",
    "\n",
    "# Display the scatter plot\n",
    "plt.show()\n",
    "\n",
    "# Save the top 18 features with the target variable to CSV\n",
    "important_features_data = df[top_features['Feature'].tolist() + ['Number_of_days_until_sale']]\n",
    "important_features_data.to_csv('important_features_data_xgboost.csv', index=False)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", cv_r2_scores_xgb)\n",
    "print(\"Cross-Validation MAE scores:\", cv_mae_scores_xgb)\n",
    "print(\"Cross-Validation RMSE scores:\", cv_rmse_scores_xgb)\n",
    "print(\"\\nTraining Set R-squared:\", train_r2)\n",
    "print(\"Training Set MAE:\", train_mae)\n",
    "print(\"Training Set RMSE:\", train_rmse)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65674da1-402a-4f34-b988-99dbf383ef3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with important features for XGBoost\n",
    "important_features_data_xgboost = pd.read_csv('important_features_data_xgboost.csv')\n",
    "\n",
    "# Display the column names (variable names)\n",
    "variable_names_xgboost = important_features_data_xgboost.columns.tolist()\n",
    "print(\"Variable Names in 'important_features_data_xgboost.csv':\")\n",
    "print(variable_names_xgboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e4574-76f4-42ba-81b5-5ac1d471fe5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('important_features_data_xgboost.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = xgb_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='purple')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - XGBoost (Top 18 features)')\n",
    "plt.savefig('actual_vs_predicted_xgboost_Builtin.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", xgb_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", xgb_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb679c2-6789-4296-b48a-954db4f083dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reduced_df_rfecvdt.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = xgb_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - XGBoost (RFECV)')\n",
    "plt.savefig('actual_vs_predicted_xgboost_RFECV.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", xgb_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", xgb_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e3cae-fdb2-4c85-906a-c2119ee3cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catboost full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f752c5-2845-47aa-9c4b-32f29ecac044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('df_encoded.csv')  # Replace with your actual file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)  # Replace with your target column name\n",
    "y = df['Number_of_days_until_sale']               # Replace with your target column name\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost_model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "\n",
    "# Perform 3-fold cross-validation on the training data and calculate metrics\n",
    "cv_r2_scores_catboost = cross_val_score(catboost_model, X_train, y_train, cv=3, scoring='r2')\n",
    "cv_mae_scores_catboost = -cross_val_score(catboost_model, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')\n",
    "cv_rmse_scores_catboost = np.sqrt(-cross_val_score(catboost_model, X_train, y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Train the model on the training set\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "y_train_pred = catboost_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_test_pred = catboost_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = catboost_model.get_feature_importance()\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Normalize the importances (scale between 0 and 1)\n",
    "importance_df['Importance'] = importance_df['Importance'] / importance_df['Importance'].max()\n",
    "\n",
    "# Select top 18 features\n",
    "top_features = importance_df.nlargest(18, 'Importance')\n",
    "\n",
    "# Plotting feature importances and saving the plot\n",
    "plt.figure(figsize=(10, 8))  # Adjust the size as needed\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n",
    "plt.title('Top 18 Features Selected by  CatBoost ')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels\n",
    "plt.yticks(rotation=45)  # Rotate y-axis labels\n",
    "plt.tight_layout()  # This will adjust spacing to accommodate labels\n",
    "plt.savefig('normalized_feature_importances_catboost_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a scatter plot of actual vs predicted values with blue dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='blue')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - CatBoost (Full dataset)')\n",
    "\n",
    "# Save the scatter plot as an image\n",
    "plt.savefig('actual_vs_predicted_CatBoost_Fulldata.png')\n",
    "\n",
    "# Display the scatter plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the top 18 features with the target variable to CSV\n",
    "important_features_data = df[top_features['Feature'].tolist() + ['Number_of_days_until_sale']]\n",
    "important_features_data.to_csv('important_features_data_catboost.csv', index=False)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", cv_r2_scores_catboost)\n",
    "print(\"Cross-Validation MAE scores:\", cv_mae_scores_catboost)\n",
    "print(\"Cross-Validation RMSE scores:\", cv_rmse_scores_catboost)\n",
    "print(\"\\nTraining Set R-squared:\", train_r2)\n",
    "print(\"Training Set MAE:\", train_mae)\n",
    "print(\"Training Set RMSE:\", train_rmse)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37cbf0-ac18-4a6d-a37d-e73c861b460e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with important features for CatBoost\n",
    "important_features_data_catboost = pd.read_csv('important_features_data_catboost.csv')\n",
    "\n",
    "# Display the column names (variable names)\n",
    "variable_names_catboost = important_features_data_catboost.columns.tolist()\n",
    "print(\"Variable Names in 'important_features_data_catboost.csv':\")\n",
    "print(variable_names_catboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff1e31-2df7-431f-8fb8-ee87216c4866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d22d40-5e68-4a9a-a0ba-63e499bc07b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('important_features_data_catboost.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid for CatBoost\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300, 400, 500],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost_model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "catboost_random = RandomizedSearchCV(estimator=catboost_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "catboost_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = catboost_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='purple')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - CatBoost (Top 18 features)')\n",
    "plt.savefig('actual_vs_predicted_catboost_Builtin.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", catboost_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", catboost_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde6556-040e-4dc2-992f-0306841e4cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reduced_df_rfecvdt.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid for CatBoost\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300, 400, 500],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost_model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "catboost_random = RandomizedSearchCV(estimator=catboost_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "catboost_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = catboost_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - CatBoost (RFECV)')\n",
    "plt.savefig('actual_vs_predicted_catboost_RFECV.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", catboost_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", catboost_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b010afe-2c8e-4d8a-989c-2f9188452e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lightgbm Fulldatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84769d-5705-4d71-9801-64effb66b80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('df_encoded.csv')  # Replace with your actual file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)  # Replace with your target column name\n",
    "y = df['Number_of_days_until_sale']               # Replace with your target column name\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Perform 3-fold cross-validation on the training data and calculate metrics\n",
    "cv_r2_scores_lgb = cross_val_score(lgb_model, X_train, y_train, cv=3, scoring='r2')\n",
    "cv_mae_scores_lgb = -cross_val_score(lgb_model, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')\n",
    "cv_rmse_scores_lgb = np.sqrt(-cross_val_score(lgb_model, X_train, y_train, cv=3, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Train the model on the training set\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "y_train_pred = lgb_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_test_pred = lgb_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = lgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Normalize the importances (scale between 0 and 1)\n",
    "importance_df['Importance'] = importance_df['Importance'] / importance_df['Importance'].max()\n",
    "\n",
    "# Select top 18 features\n",
    "top_features = importance_df.nlargest(18, 'Importance')\n",
    "\n",
    "# Plotting feature importances and saving the plot\n",
    "plt.figure(figsize=(10, 8))  # Adjust the size as needed\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n",
    "plt.title('Top 18 Features Selected by  LightGBM ')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels\n",
    "plt.yticks(rotation=45)  # Rotate y-axis labels\n",
    "plt.tight_layout()  # This will adjust spacing to accommodate labels\n",
    "plt.savefig('normalized_feature_importances_lightgbm_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot of actual vs predicted values with blue dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='blue')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - LightGBM (Full dataset)')\n",
    "\n",
    "# Save the scatter plot as an image\n",
    "plt.savefig('actual_vs_predicted_LightGBM_Fulldata.png')\n",
    "\n",
    "# Display the scatter plot\n",
    "plt.show()\n",
    "\n",
    "# Save the top 18 features with the target variable to CSV\n",
    "important_features_data = df[top_features['Feature'].tolist() + ['Number_of_days_until_sale']]\n",
    "important_features_data.to_csv('important_features_data_lightgbm.csv', index=False)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", cv_r2_scores_lgb)\n",
    "print(\"Cross-Validation MAE scores:\", cv_mae_scores_lgb)\n",
    "print(\"Cross-Validation RMSE scores:\", cv_rmse_scores_lgb)\n",
    "print(\"\\nTraining Set R-squared:\", train_r2)\n",
    "print(\"Training Set MAE:\", train_mae)\n",
    "print(\"Training Set RMSE:\", train_rmse)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b44aa-e23c-4026-b6d6-16c89bc5606e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with important features for LightGBM\n",
    "important_features_data_lightgbm = pd.read_csv('important_features_data_lightgbm.csv')\n",
    "\n",
    "# Display the column names (variable names)\n",
    "variable_names_lightgbm = important_features_data_lightgbm.columns.tolist()\n",
    "print(\"Variable Names in 'important_features_data_lightgbm.csv':\")\n",
    "print(variable_names_lightgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e4761-1b63-47b3-acbe-1c6fc7a740ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('important_features_data_lightgbm.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid for LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "# Initialize the LightGBM model with lower verbosity\n",
    "lgb_model = LGBMRegressor(random_state=42, verbosity=-1)  # Set verbosity to -1 for minimal output\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "lgb_random = RandomizedSearchCV(estimator=lgb_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "lgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = lgb_random.predict(X_test)\n",
    "\n",
    "# Create and save a plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='purple')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - LightGBM (Top 18 features)')\n",
    "plt.savefig('actual_vs_predicted_lightgbm_Builtin.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", lgb_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", lgb_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd4f50-4995-41e7-a0d8-dcae62880ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reduced_df_rfecvdt.csv')  # Replace with your file path\n",
    "\n",
    "# Separating the target variable and the features\n",
    "X = df.drop('Number_of_days_until_sale', axis=1)\n",
    "y = df['Number_of_days_until_sale']\n",
    "\n",
    "# Splitting the data into training (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid for LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "# Initialize the LightGBM model with lower verbosity\n",
    "lgb_model = LGBMRegressor(random_state=42, verbosity=-1)  # Set verbosity to -1 for minimal output\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "lgb_random = RandomizedSearchCV(estimator=lgb_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "lgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best found parameters\n",
    "y_test_pred = lgb_random.predict(X_test)\n",
    "\n",
    "# Create and save a scatter plot of actual vs predicted values with purple dots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_test_pred, color='green')  # Set color to 'purple' for the dots\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values - LightGBM (RFECV)')\n",
    "plt.savefig('actual_vs_predicted_lightgbm_RFECV.png')\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Cross-Validation R-squared scores:\", lgb_random.best_score_)\n",
    "print(\"Best Hyperparameters:\", lgb_random.best_params_)\n",
    "print(\"\\nTest Set R-squared:\", test_r2)\n",
    "print(\"Test Set MAE:\", test_mae)\n",
    "print(\"Test Set RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1fa88-5029-4d24-8173-3ab8ca5aeb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5861e-74e9-4ea0-8f41-e38834044c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016b6e4-5895-4282-a395-7bf8f7863b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70270a-8e8d-417e-979e-7b646174403f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"Scikit-learn Version:\", sklearn.__version__)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "print(\"RFECV Version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9de039-7b08-4931-adc8-41cfe14555ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
